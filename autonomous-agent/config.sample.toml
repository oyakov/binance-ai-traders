[llm]
base_url = "http://llm:11434/v1"
model = "llama3.1:8b-instruct"
request_timeout = 120

[agent]
workspace = "."
auto_plan = true
max_iterations = 12

[mcp]
enabled = true
servers = [
  { name = "filesystem", command = "python", args = ["-m", "autonomous_agent.mcp.servers.filesystem"], cwd = "." }
]
